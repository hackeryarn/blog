<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Efficient CSV imports in Rails - Artem Chernyak&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Artem Chernyak" />
  <meta name="description" content="Rails has great capabilities for working CSV files. However, like with many things, the most obvious way is not the most efficient.
We noticed this when our server had major fluctuations in memory consumption. After digging through metrics, made easy thanks to Prometheus and Grafana. We noticed that the spikes were due to our CSV uploads.
Examining CSV import Our processor is responsible for bringing in coordinates from legacy systems and ones that cannot support our API." />

  <meta name="keywords" content="blog, go, golang, js, javascript, tech" />






<meta name="generator" content="Hugo 0.41" />


<link rel="canonical" href="http://localhost:1313/post/rails-csv-imports/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">







<link href="/dist/even.min.css?v=3.1.1" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="Efficient CSV imports in Rails" />
<meta property="og:description" content="Rails has great capabilities for working CSV files. However, like with many things, the most obvious way is not the most efficient.
We noticed this when our server had major fluctuations in memory consumption. After digging through metrics, made easy thanks to Prometheus and Grafana. We noticed that the spikes were due to our CSV uploads.
Examining CSV import Our processor is responsible for bringing in coordinates from legacy systems and ones that cannot support our API." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/post/rails-csv-imports/" />



<meta property="article:published_time" content="2017-06-11T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2017-06-11T00:00:00&#43;00:00"/>











<meta itemprop="name" content="Efficient CSV imports in Rails">
<meta itemprop="description" content="Rails has great capabilities for working CSV files. However, like with many things, the most obvious way is not the most efficient.
We noticed this when our server had major fluctuations in memory consumption. After digging through metrics, made easy thanks to Prometheus and Grafana. We noticed that the spikes were due to our CSV uploads.
Examining CSV import Our processor is responsible for bringing in coordinates from legacy systems and ones that cannot support our API.">


<meta itemprop="datePublished" content="2017-06-11T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2017-06-11T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="581">



<meta itemprop="keywords" content="guide," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Efficient CSV imports in Rails"/>
<meta name="twitter:description" content="Rails has great capabilities for working CSV files. However, like with many things, the most obvious way is not the most efficient.
We noticed this when our server had major fluctuations in memory consumption. After digging through metrics, made easy thanks to Prometheus and Grafana. We noticed that the spikes were due to our CSV uploads.
Examining CSV import Our processor is responsible for bringing in coordinates from legacy systems and ones that cannot support our API."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Artem Chernyak</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Artem Chernyak</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Efficient CSV imports in Rails</h1>

      <div class="post-meta">
        <span class="post-time"> 2017-06-11 </span>
        <div class="post-category">
            
              <a href="/categories/ruby/"> Ruby </a>
            
              <a href="/categories/rails/"> Rails </a>
            
          </div>
        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#examining-csv-import">Examining CSV import</a></li>
<li><a href="#better-parsing-method">Better parsing method</a></li>
<li><a href="#reducing-the-number-of-creates">Reducing the number of creates</a></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<p>Rails has great capabilities for working CSV files. However, like with many
things, the most obvious way is not the most efficient.</p>

<p>We noticed this when our server had major fluctuations in memory consumption.
After digging through metrics, made easy thanks to
<a href="https://prometheus.io">Prometheus</a> and <a href="https://grafana.com">Grafana</a>. We noticed that the spikes were due to our CSV
uploads.</p>

<h1 id="examining-csv-import">Examining CSV import</h1>

<p>Our processor is responsible for bringing in coordinates
from legacy systems and ones that cannot support our API.</p>

<p>The original code:</p>

<pre><code>require 'csv'

class CsvProcessor
  def self.import_locations(file)
    CSV.parse(file.read) do |row|
      Location.create(
        name: row['Name'],
        lat: row['Lat'],
        lon: row['Lon']
      )
    end
  end
end
</code></pre>

<p>Looking at this code, I quickly came to the assumption that
<code>read</code> was storing the entire file in memory before parsing.
Which sent me on a search for a more efficient parsing method.</p>

<h1 id="better-parsing-method">Better parsing method</h1>

<p>Through my search, I came across an amazingly detailed <a href="https://dalibornasevic.com/posts/68-processing-large-csv-files-with-ruby">article</a> on how to get the
most memory efficient reads possible. It turns out, we were using the least
efficient method to parse CSV files. I won&rsquo;t put all the statistics here because
the original article does a great deep dive on all the possibilities.
I will only include the most efficient method, and the one we used.</p>

<p>Efficient read code:</p>

<pre><code>require 'csv'

class CsvProcessor
  def self.import_locations(file)
    CSV.foreach(file) do |row|
      Location.create(
        name: row['Name'],
        lat: row['Lat'],
        lon: row['Lon']
      )
    end
  end
end
</code></pre>

<p>The change was minor. I had to use <code>CSV.foreach</code> instead of <code>CSV.parse</code> which
performs a line by line streaming traversal of the file. When working with files
it is beneficial to have a stream. Streams only stores as much information as
needed during each cycle. In this case, it only needs one line.</p>

<p>I also got to eliminate the manual read. This cleaned up my code a bit, and I was
more than happy to let <code>CSV.foreach</code> handle the reading for me.</p>

<p>This one change eliminated our memory spikes. Making CSV imports a
minor event for the server.</p>

<h1 id="reducing-the-number-of-creates">Reducing the number of creates</h1>

<p>However, while looking a the metrics around CSV imports I also noticed that it
took a long time to import a CSV. The most glaring suspect was the <code>create</code> on
every row.</p>

<p>Rails libraries come to the rescue! There is a great library,
<a href="https://github.com/zdennis/activerecord-import">activerecord-import</a>, which allows for a singe database transaction for multiple
creates and doesn&rsquo;t complicate the code much.</p>

<p>I eagerly tried to insert all the records in a single transaction. Although this
had some speed improvement, it shot up our memory consumption again. So I started
experimenting with intervals. With some trial and error, I arrived at 200
records per transaction. It didn&rsquo;t consume too much memory and was actually the
fastest. Anything below 200 created too many transactions and the efficiency
dropped. Anything above 200 was creating too large of transactions for them to
be efficiently saved.</p>

<p>My final code:</p>

<pre><code>require 'csv'

class CsvProcessor
  def self.import_locations(file)
    locations = []
    CSV.foreach(file) do |row|
      locations &lt;&lt; Location.new(
        name: row['Name'],
        lat: row['Lat'],
        lon: row['Lon']
      )

      if locations.length &gt; 200
        Location.import locations
        locations = []
      end
    end

    Location.import locations
  end
end
</code></pre>

<p>This change required a bit more code. I had to maintain a list of locations to
import. Which I checked for the appropriate length, 200, every
iteration.</p>

<p>Once the file read was complete. I performed a final import to save
any remaining locations. If the list was empty, it would
result in no import.</p>

<p>This final change improved our import time over 10x and made this small project
much more worth it!</p>

    </div>

    
    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Artem Chernyak</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">2017-06-11</span>
  </p>
  
  
</div>

    
    

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/guide/">guide</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/lodash/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">How Lodash worked itself out of a job</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/phoenix-talk/">
            <span class="next-text nav-default">Phoenix talk</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="http://localhost:1313" class="iconfont icon-twitter" title="twitter"></a>
      <a href="http://localhost:1313" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="http://localhost:1313" class="iconfont icon-github" title="github"></a>
  <a href="http://localhost:1313/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Artem Chernyak</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.1.1"></script>








</body>
</html>
